신경망에서는 활성화 함수로 비선형 함수를 사용해야 합니다 달리 말하면 
선형함수를 사용해서는 안됩니다.
그 이유는 바로 선형함수를 이용하면 신경망의 층을 깊게 하는 의미가 없어지기 떄문입니다 
선형 함수의 문제는 층을 아무리 깊게 해도 '은닉층이 없는 네트워크'로도 똑같은 기능을 할수 
있다는 데 있습니다. 구체적인 예로 h(x)=cx를 활성화 함수로 사용한 3층
네트워크를 떠올리면 y(x)=h(h(h(x)))가 됩니다 이 계산은 
y=c*c*c*x처럼 곱셈을 세번 수행하지만 y=ax(a=c**3)일 뿐이죠
